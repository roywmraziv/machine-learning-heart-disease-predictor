{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tdCR9BwFfVAB"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install torch\n",
        "%pip install torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oIGKCFJDfaCw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBBXNa4xfe57",
        "outputId": "33ec4062-44f3-45de-8042-05de60206a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   age  sex  chest pain type  resting bp s  cholesterol  fasting blood sugar  \\\n",
            "0   40    1                2           140          289                    0   \n",
            "1   49    0                3           160          180                    0   \n",
            "2   37    1                2           130          283                    0   \n",
            "3   48    0                4           138          214                    0   \n",
            "4   54    1                3           150          195                    0   \n",
            "5   39    1                3           120          339                    0   \n",
            "6   45    0                2           130          237                    0   \n",
            "7   54    1                2           110          208                    0   \n",
            "8   37    1                4           140          207                    0   \n",
            "9   48    0                2           120          284                    0   \n",
            "\n",
            "   resting ecg  max heart rate  exercise angina  oldpeak  ST slope  target  \n",
            "0            0             172                0      0.0         1       0  \n",
            "1            0             156                0      1.0         2       1  \n",
            "2            1              98                0      0.0         1       0  \n",
            "3            0             108                1      1.5         2       1  \n",
            "4            0             122                0      0.0         1       0  \n",
            "5            0             170                0      0.0         1       0  \n",
            "6            0             170                0      0.0         1       0  \n",
            "7            0             142                0      0.0         1       0  \n",
            "8            0             130                1      1.5         2       1  \n",
            "9            0             120                0      0.0         1       0  \n"
          ]
        }
      ],
      "source": [
        "# Load the heart disease dataset\n",
        "data = pd.read_csv('heart_disease_dataset.csv')\n",
        "print(data.head(10))\n",
        "\n",
        "# Split features and target variable\n",
        "X = data.drop(columns=['target'])\n",
        "y = data['target']\n",
        "\n",
        "# Convert dataframe to PyTorch tensors\n",
        "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_tensor)\n",
        "\n",
        "# Training split 1 is 80/10/10\n",
        "# Training split 2 is 70/15/15\n",
        "# Training split 3 is 60/20/20\n",
        "\n",
        "split_num = input(\"Training split 1, 2, or 3: \")\n",
        "\n",
        "if split_num == \"1\":\n",
        "  X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_tensor, test_size=0.2, random_state=42)\n",
        "  X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "elif split_num == \"2\":\n",
        "  X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_tensor, test_size=0.3, random_state=42)\n",
        "  X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "elif split_num == \"3\":\n",
        "  X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_tensor, test_size=0.4, random_state=42)\n",
        "  X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6VgkshRjcO_"
      },
      "outputs": [],
      "source": [
        "# Define custom dataset for PyTorch\n",
        "class HeartDiseaseDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUwcUs9Djfl9",
        "outputId": "1e92cb18-ef3f-4a67-b5f3-6e983908e121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Define the batch size: 50\n"
          ]
        }
      ],
      "source": [
        "# Create dataset and dataloaders\n",
        "train_dataset = HeartDiseaseDataset(X_train, y_train)\n",
        "valid_dataset = HeartDiseaseDataset(X_valid, y_valid)\n",
        "test_dataset = HeartDiseaseDataset(X_test, y_test)\n",
        "\n",
        "# Batch size of 1 means each change is based of off a single training example\n",
        "# Batch size of 50 is medium size with a stable convergence\n",
        "# Batch size of 250+ is slow convergence and bad generalization but efficient\n",
        "batch_size = int(input(\"Define the batch size: \"))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMgebx_RjpQu"
      },
      "outputs": [],
      "source": [
        "# Define the first model\n",
        "class HeartDiseaseModel1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HeartDiseaseModel1, self).__init__()\n",
        "        input_size = X_train.shape[1]\n",
        "\n",
        "        #This dymanic first layer is fully connected as it takes input_size neurons\n",
        "        self.fc1 = nn.Linear(input_size, 400)\n",
        "\n",
        "        # ReLU refers to Rectified Linear Unit and is a common activation function\n",
        "        # its a piecewise linear function that outputs the input directly if positive\n",
        "        # if the input is negative, it outputs 0\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.fc2 = nn.Linear(400, 1)\n",
        "\n",
        "        #Final layer applies the sigmoid function to force the output between 0 and 1\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "#Define the second model\n",
        "# this model has one less layer and far less neurons compared to the other models\n",
        "class HeartDiseaseModel2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HeartDiseaseModel2, self).__init__()\n",
        "        self.fc1 = nn.Linear(11, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))  # Activation function for first layer\n",
        "        x = F.relu(self.fc2(x))  # Activation function for second layer\n",
        "        x = torch.sigmoid(self.fc3(x))  # Sigmoid activation for output layer\n",
        "        return x\n",
        "\n",
        "#Define the third model\n",
        "# This model is exceptionally similar to the first one but with an extra layer\n",
        "class HeartDiseaseModel3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HeartDiseaseModel3, self).__init__()\n",
        "        input_size = X_train.shape[1]\n",
        "        # This dynamic first layer is fully connected as it takes input_size neurons\n",
        "        self.fc1 = nn.Linear(input_size, 400)\n",
        "\n",
        "        # Adding an additional fully connected layer\n",
        "        self.fc2 = nn.Linear(400, 50)  # New layer with 50 neurons\n",
        "\n",
        "        # same as teh original\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.fc3 = nn.Linear(50, 1)\n",
        "\n",
        "        # Final layer applies the sigmoid function to force the output between 0 and 1\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyyu4UZq-ZNY",
        "outputId": "e0a0ded6-9c2e-48af-8e03-610347fdc7a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 1, 2, or 3: 3\n",
            "Learning rate 1, 2, 3, or 4: 3\n"
          ]
        }
      ],
      "source": [
        "num = input(\"Test 1, 2, or 3: \")\n",
        "# Initialize the model and move it to the GPU if available\n",
        "if num == \"1\":\n",
        "  model = HeartDiseaseModel1()\n",
        "elif num == \"2\":\n",
        "  model = HeartDiseaseModel2()\n",
        "elif num == \"3\":\n",
        "  model = HeartDiseaseModel3()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "LR = input(\"Learning rate 1, 2, 3, or 4: \")\n",
        "if LR == \"1\":\n",
        "  LEARNING_RATE = 0.01 #the model will learn very quickly\n",
        "elif LR == \"2\":\n",
        "  LEARNING_RATE = 0.001 # not too slow but not too fast\n",
        "elif LR == \"3\":\n",
        "  LEARNING_RATE = 0.0001 # good for gradual changes, unlikely to overshoot loss function\n",
        "elif LR == \"4\":\n",
        "  LEARNING_RATE = 0.00001 # incredibly slow, very fine tuning\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvQx8da5koJ_",
        "outputId": "0f0964d2-2bac-4c60-b9dc-96c0004b065f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many epochs: 50\n",
            "Epoch 1/50\n",
            "Step 1 / 20, Loss: 0.6986067295074463\n",
            "Step 2 / 20, Loss: 0.6906841397285461\n",
            "Step 3 / 20, Loss: 0.6908621788024902\n",
            "Step 4 / 20, Loss: 0.6818970441818237\n",
            "Step 5 / 20, Loss: 0.6911101341247559\n",
            "Step 6 / 20, Loss: 0.6770676374435425\n",
            "Step 7 / 20, Loss: 0.6756614446640015\n",
            "Step 8 / 20, Loss: 0.6632146239280701\n",
            "Step 9 / 20, Loss: 0.6759188175201416\n",
            "Step 10 / 20, Loss: 0.6555429697036743\n",
            "Step 11 / 20, Loss: 0.6740960478782654\n",
            "Step 12 / 20, Loss: 0.6590105295181274\n",
            "Step 13 / 20, Loss: 0.6565342545509338\n",
            "Step 14 / 20, Loss: 0.6671660542488098\n",
            "Step 15 / 20, Loss: 0.6605589389801025\n",
            "Step 16 / 20, Loss: 0.6643780469894409\n",
            "Step 17 / 20, Loss: 0.6549785733222961\n",
            "Step 18 / 20, Loss: 0.660632312297821\n",
            "Step 19 / 20, Loss: 0.6423093676567078\n",
            "Step 20 / 20, Loss: 0.7053725719451904\n",
            "Epoch 2/50\n",
            "Step 1 / 20, Loss: 0.6418484449386597\n",
            "Step 2 / 20, Loss: 0.6442711353302002\n",
            "Step 3 / 20, Loss: 0.6399983167648315\n",
            "Step 4 / 20, Loss: 0.6288543343544006\n",
            "Step 5 / 20, Loss: 0.624051570892334\n",
            "Step 6 / 20, Loss: 0.6381515264511108\n",
            "Step 7 / 20, Loss: 0.6345669031143188\n",
            "Step 8 / 20, Loss: 0.6303246021270752\n",
            "Step 9 / 20, Loss: 0.6231459975242615\n",
            "Step 10 / 20, Loss: 0.6057436466217041\n",
            "Step 11 / 20, Loss: 0.6079607605934143\n",
            "Step 12 / 20, Loss: 0.6056411266326904\n",
            "Step 13 / 20, Loss: 0.6135659217834473\n",
            "Step 14 / 20, Loss: 0.6234419345855713\n",
            "Step 15 / 20, Loss: 0.6061975359916687\n",
            "Step 16 / 20, Loss: 0.6267139911651611\n",
            "Step 17 / 20, Loss: 0.6146039366722107\n",
            "Step 18 / 20, Loss: 0.5908098816871643\n",
            "Step 19 / 20, Loss: 0.6268996596336365\n",
            "Step 20 / 20, Loss: 0.5201804637908936\n",
            "Epoch 3/50\n",
            "Step 1 / 20, Loss: 0.6133431196212769\n",
            "Step 2 / 20, Loss: 0.6098864674568176\n",
            "Step 3 / 20, Loss: 0.5890577435493469\n",
            "Step 4 / 20, Loss: 0.590459942817688\n",
            "Step 5 / 20, Loss: 0.5975666642189026\n",
            "Step 6 / 20, Loss: 0.5842111706733704\n",
            "Step 7 / 20, Loss: 0.5669159889221191\n",
            "Step 8 / 20, Loss: 0.5480367541313171\n",
            "Step 9 / 20, Loss: 0.582224428653717\n",
            "Step 10 / 20, Loss: 0.5746503472328186\n",
            "Step 11 / 20, Loss: 0.5689594149589539\n",
            "Step 12 / 20, Loss: 0.5756319165229797\n",
            "Step 13 / 20, Loss: 0.5614365935325623\n",
            "Step 14 / 20, Loss: 0.5632836222648621\n",
            "Step 15 / 20, Loss: 0.5782896876335144\n",
            "Step 16 / 20, Loss: 0.5714301466941833\n",
            "Step 17 / 20, Loss: 0.5150082111358643\n",
            "Step 18 / 20, Loss: 0.527894914150238\n",
            "Step 19 / 20, Loss: 0.5836598873138428\n",
            "Step 20 / 20, Loss: 0.3409911096096039\n",
            "Epoch 4/50\n",
            "Step 1 / 20, Loss: 0.5569242835044861\n",
            "Step 2 / 20, Loss: 0.5633721351623535\n",
            "Step 3 / 20, Loss: 0.5609518885612488\n",
            "Step 4 / 20, Loss: 0.5071052312850952\n",
            "Step 5 / 20, Loss: 0.5472794771194458\n",
            "Step 6 / 20, Loss: 0.5240543484687805\n",
            "Step 7 / 20, Loss: 0.5193582773208618\n",
            "Step 8 / 20, Loss: 0.5172408819198608\n",
            "Step 9 / 20, Loss: 0.5543201565742493\n",
            "Step 10 / 20, Loss: 0.4808630049228668\n",
            "Step 11 / 20, Loss: 0.5460190773010254\n",
            "Step 12 / 20, Loss: 0.5112112164497375\n",
            "Step 13 / 20, Loss: 0.49777764081954956\n",
            "Step 14 / 20, Loss: 0.5111802220344543\n",
            "Step 15 / 20, Loss: 0.5182828903198242\n",
            "Step 16 / 20, Loss: 0.5182088613510132\n",
            "Step 17 / 20, Loss: 0.5437958240509033\n",
            "Step 18 / 20, Loss: 0.5278171300888062\n",
            "Step 19 / 20, Loss: 0.5203657746315002\n",
            "Step 20 / 20, Loss: 0.6102765798568726\n",
            "Epoch 5/50\n",
            "Step 1 / 20, Loss: 0.4987635910511017\n",
            "Step 2 / 20, Loss: 0.4946615993976593\n",
            "Step 3 / 20, Loss: 0.4543520212173462\n",
            "Step 4 / 20, Loss: 0.5201583504676819\n",
            "Step 5 / 20, Loss: 0.5061125159263611\n",
            "Step 6 / 20, Loss: 0.5622033476829529\n",
            "Step 7 / 20, Loss: 0.5219951272010803\n",
            "Step 8 / 20, Loss: 0.5139995813369751\n",
            "Step 9 / 20, Loss: 0.49553805589675903\n",
            "Step 10 / 20, Loss: 0.4680315852165222\n",
            "Step 11 / 20, Loss: 0.5057929754257202\n",
            "Step 12 / 20, Loss: 0.49745965003967285\n",
            "Step 13 / 20, Loss: 0.5149021744728088\n",
            "Step 14 / 20, Loss: 0.42842528223991394\n",
            "Step 15 / 20, Loss: 0.46666276454925537\n",
            "Step 16 / 20, Loss: 0.41685277223587036\n",
            "Step 17 / 20, Loss: 0.4978690445423126\n",
            "Step 18 / 20, Loss: 0.4887530207633972\n",
            "Step 19 / 20, Loss: 0.44699469208717346\n",
            "Step 20 / 20, Loss: 0.2972552180290222\n",
            "Epoch 6/50\n",
            "Step 1 / 20, Loss: 0.45861610770225525\n",
            "Step 2 / 20, Loss: 0.47527968883514404\n",
            "Step 3 / 20, Loss: 0.5451546311378479\n",
            "Step 4 / 20, Loss: 0.39051002264022827\n",
            "Step 5 / 20, Loss: 0.4293820261955261\n",
            "Step 6 / 20, Loss: 0.5169618725776672\n",
            "Step 7 / 20, Loss: 0.4202311336994171\n",
            "Step 8 / 20, Loss: 0.44828808307647705\n",
            "Step 9 / 20, Loss: 0.4322342276573181\n",
            "Step 10 / 20, Loss: 0.4776122272014618\n",
            "Step 11 / 20, Loss: 0.47829878330230713\n",
            "Step 12 / 20, Loss: 0.45252373814582825\n",
            "Step 13 / 20, Loss: 0.48497676849365234\n",
            "Step 14 / 20, Loss: 0.4846017062664032\n",
            "Step 15 / 20, Loss: 0.434824138879776\n",
            "Step 16 / 20, Loss: 0.42377910017967224\n",
            "Step 17 / 20, Loss: 0.4842851161956787\n",
            "Step 18 / 20, Loss: 0.43148574233055115\n",
            "Step 19 / 20, Loss: 0.4276663661003113\n",
            "Step 20 / 20, Loss: 0.3269314765930176\n",
            "Epoch 7/50\n",
            "Step 1 / 20, Loss: 0.37984973192214966\n",
            "Step 2 / 20, Loss: 0.4266054034233093\n",
            "Step 3 / 20, Loss: 0.3930300772190094\n",
            "Step 4 / 20, Loss: 0.49835121631622314\n",
            "Step 5 / 20, Loss: 0.4022361636161804\n",
            "Step 6 / 20, Loss: 0.48451006412506104\n",
            "Step 7 / 20, Loss: 0.48194968700408936\n",
            "Step 8 / 20, Loss: 0.32256123423576355\n",
            "Step 9 / 20, Loss: 0.4265404939651489\n",
            "Step 10 / 20, Loss: 0.49024927616119385\n",
            "Step 11 / 20, Loss: 0.39585793018341064\n",
            "Step 12 / 20, Loss: 0.47367775440216064\n",
            "Step 13 / 20, Loss: 0.47561967372894287\n",
            "Step 14 / 20, Loss: 0.3632259666919708\n",
            "Step 15 / 20, Loss: 0.40698137879371643\n",
            "Step 16 / 20, Loss: 0.3587053418159485\n",
            "Step 17 / 20, Loss: 0.45329171419143677\n",
            "Step 18 / 20, Loss: 0.5413941144943237\n",
            "Step 19 / 20, Loss: 0.4619719982147217\n",
            "Step 20 / 20, Loss: 0.2850295901298523\n",
            "Epoch 8/50\n",
            "Step 1 / 20, Loss: 0.3714836835861206\n",
            "Step 2 / 20, Loss: 0.42198246717453003\n",
            "Step 3 / 20, Loss: 0.3930895924568176\n",
            "Step 4 / 20, Loss: 0.37069085240364075\n",
            "Step 5 / 20, Loss: 0.35446712374687195\n",
            "Step 6 / 20, Loss: 0.3512080907821655\n",
            "Step 7 / 20, Loss: 0.4180159866809845\n",
            "Step 8 / 20, Loss: 0.41048985719680786\n",
            "Step 9 / 20, Loss: 0.4690982401371002\n",
            "Step 10 / 20, Loss: 0.42108505964279175\n",
            "Step 11 / 20, Loss: 0.4256616234779358\n",
            "Step 12 / 20, Loss: 0.48407799005508423\n",
            "Step 13 / 20, Loss: 0.4592318832874298\n",
            "Step 14 / 20, Loss: 0.36721476912498474\n",
            "Step 15 / 20, Loss: 0.28449681401252747\n",
            "Step 16 / 20, Loss: 0.46570342779159546\n",
            "Step 17 / 20, Loss: 0.42233505845069885\n",
            "Step 18 / 20, Loss: 0.571348249912262\n",
            "Step 19 / 20, Loss: 0.43200838565826416\n",
            "Step 20 / 20, Loss: 0.24606284499168396\n",
            "Epoch 9/50\n",
            "Step 1 / 20, Loss: 0.42862555384635925\n",
            "Step 2 / 20, Loss: 0.3836660385131836\n",
            "Step 3 / 20, Loss: 0.3657512366771698\n",
            "Step 4 / 20, Loss: 0.41170579195022583\n",
            "Step 5 / 20, Loss: 0.36174410581588745\n",
            "Step 6 / 20, Loss: 0.32176491618156433\n",
            "Step 7 / 20, Loss: 0.44684749841690063\n",
            "Step 8 / 20, Loss: 0.44006145000457764\n",
            "Step 9 / 20, Loss: 0.37047743797302246\n",
            "Step 10 / 20, Loss: 0.3603968918323517\n",
            "Step 11 / 20, Loss: 0.508766770362854\n",
            "Step 12 / 20, Loss: 0.4403154253959656\n",
            "Step 13 / 20, Loss: 0.3961816728115082\n",
            "Step 14 / 20, Loss: 0.3390938639640808\n",
            "Step 15 / 20, Loss: 0.34195953607559204\n",
            "Step 16 / 20, Loss: 0.3477460443973541\n",
            "Step 17 / 20, Loss: 0.36800816655158997\n",
            "Step 18 / 20, Loss: 0.5530998706817627\n",
            "Step 19 / 20, Loss: 0.4768233597278595\n",
            "Step 20 / 20, Loss: 0.12438565492630005\n",
            "Epoch 10/50\n",
            "Step 1 / 20, Loss: 0.41393402218818665\n",
            "Step 2 / 20, Loss: 0.3947409689426422\n",
            "Step 3 / 20, Loss: 0.3130837082862854\n",
            "Step 4 / 20, Loss: 0.47058337926864624\n",
            "Step 5 / 20, Loss: 0.4021354913711548\n",
            "Step 6 / 20, Loss: 0.4363115727901459\n",
            "Step 7 / 20, Loss: 0.4101875424385071\n",
            "Step 8 / 20, Loss: 0.463836669921875\n",
            "Step 9 / 20, Loss: 0.4158939719200134\n",
            "Step 10 / 20, Loss: 0.40617474913597107\n",
            "Step 11 / 20, Loss: 0.5712020993232727\n",
            "Step 12 / 20, Loss: 0.43063220381736755\n",
            "Step 13 / 20, Loss: 0.29567667841911316\n",
            "Step 14 / 20, Loss: 0.31162509322166443\n",
            "Step 15 / 20, Loss: 0.34784069657325745\n",
            "Step 16 / 20, Loss: 0.28053992986679077\n",
            "Step 17 / 20, Loss: 0.34943756461143494\n",
            "Step 18 / 20, Loss: 0.33894243836402893\n",
            "Step 19 / 20, Loss: 0.37811964750289917\n",
            "Step 20 / 20, Loss: 1.6837214231491089\n",
            "Epoch 11/50\n",
            "Step 1 / 20, Loss: 0.41192254424095154\n",
            "Step 2 / 20, Loss: 0.3169092535972595\n",
            "Step 3 / 20, Loss: 0.4466091990470886\n",
            "Step 4 / 20, Loss: 0.36950284242630005\n",
            "Step 5 / 20, Loss: 0.43279510736465454\n",
            "Step 6 / 20, Loss: 0.3954777419567108\n",
            "Step 7 / 20, Loss: 0.3208225965499878\n",
            "Step 8 / 20, Loss: 0.3746044933795929\n",
            "Step 9 / 20, Loss: 0.32340365648269653\n",
            "Step 10 / 20, Loss: 0.3839905858039856\n",
            "Step 11 / 20, Loss: 0.3701122999191284\n",
            "Step 12 / 20, Loss: 0.45141640305519104\n",
            "Step 13 / 20, Loss: 0.4309239983558655\n",
            "Step 14 / 20, Loss: 0.32186976075172424\n",
            "Step 15 / 20, Loss: 0.396129310131073\n",
            "Step 16 / 20, Loss: 0.4645770192146301\n",
            "Step 17 / 20, Loss: 0.4105311930179596\n",
            "Step 18 / 20, Loss: 0.44809284806251526\n",
            "Step 19 / 20, Loss: 0.35734185576438904\n",
            "Step 20 / 20, Loss: 0.3707662522792816\n",
            "Epoch 12/50\n",
            "Step 1 / 20, Loss: 0.3803020119667053\n",
            "Step 2 / 20, Loss: 0.5847130417823792\n",
            "Step 3 / 20, Loss: 0.3327060639858246\n",
            "Step 4 / 20, Loss: 0.4334481358528137\n",
            "Step 5 / 20, Loss: 0.3293185532093048\n",
            "Step 6 / 20, Loss: 0.3358525335788727\n",
            "Step 7 / 20, Loss: 0.2882388234138489\n",
            "Step 8 / 20, Loss: 0.3105713427066803\n",
            "Step 9 / 20, Loss: 0.43489569425582886\n",
            "Step 10 / 20, Loss: 0.4197106659412384\n",
            "Step 11 / 20, Loss: 0.3689602017402649\n",
            "Step 12 / 20, Loss: 0.3892090618610382\n",
            "Step 13 / 20, Loss: 0.4173192083835602\n",
            "Step 14 / 20, Loss: 0.3355359137058258\n",
            "Step 15 / 20, Loss: 0.43672245740890503\n",
            "Step 16 / 20, Loss: 0.46111077070236206\n",
            "Step 17 / 20, Loss: 0.4012262225151062\n",
            "Step 18 / 20, Loss: 0.3336007595062256\n",
            "Step 19 / 20, Loss: 0.3761151134967804\n",
            "Step 20 / 20, Loss: 0.06630472838878632\n",
            "Epoch 13/50\n",
            "Step 1 / 20, Loss: 0.2992440462112427\n",
            "Step 2 / 20, Loss: 0.3573845624923706\n",
            "Step 3 / 20, Loss: 0.5065153241157532\n",
            "Step 4 / 20, Loss: 0.42712584137916565\n",
            "Step 5 / 20, Loss: 0.35540640354156494\n",
            "Step 6 / 20, Loss: 0.309970885515213\n",
            "Step 7 / 20, Loss: 0.5409935712814331\n",
            "Step 8 / 20, Loss: 0.32811927795410156\n",
            "Step 9 / 20, Loss: 0.30646660923957825\n",
            "Step 10 / 20, Loss: 0.49821680784225464\n",
            "Step 11 / 20, Loss: 0.43421638011932373\n",
            "Step 12 / 20, Loss: 0.3720729947090149\n",
            "Step 13 / 20, Loss: 0.46398571133613586\n",
            "Step 14 / 20, Loss: 0.3385527729988098\n",
            "Step 15 / 20, Loss: 0.348657488822937\n",
            "Step 16 / 20, Loss: 0.291750431060791\n",
            "Step 17 / 20, Loss: 0.3571206033229828\n",
            "Step 18 / 20, Loss: 0.3934191167354584\n",
            "Step 19 / 20, Loss: 0.32951927185058594\n",
            "Step 20 / 20, Loss: 0.4990740120410919\n",
            "Epoch 14/50\n",
            "Step 1 / 20, Loss: 0.32467254996299744\n",
            "Step 2 / 20, Loss: 0.36710837483406067\n",
            "Step 3 / 20, Loss: 0.40279296040534973\n",
            "Step 4 / 20, Loss: 0.4888620376586914\n",
            "Step 5 / 20, Loss: 0.46370944380760193\n",
            "Step 6 / 20, Loss: 0.3062015175819397\n",
            "Step 7 / 20, Loss: 0.3586629629135132\n",
            "Step 8 / 20, Loss: 0.3461129665374756\n",
            "Step 9 / 20, Loss: 0.3830762207508087\n",
            "Step 10 / 20, Loss: 0.4225793480873108\n",
            "Step 11 / 20, Loss: 0.4070480465888977\n",
            "Step 12 / 20, Loss: 0.48206111788749695\n",
            "Step 13 / 20, Loss: 0.3393484354019165\n",
            "Step 14 / 20, Loss: 0.29266557097435\n",
            "Step 15 / 20, Loss: 0.3249415457248688\n",
            "Step 16 / 20, Loss: 0.4603683352470398\n",
            "Step 17 / 20, Loss: 0.26584702730178833\n",
            "Step 18 / 20, Loss: 0.4559275805950165\n",
            "Step 19 / 20, Loss: 0.3271893262863159\n",
            "Step 20 / 20, Loss: 0.09636421501636505\n",
            "Epoch 15/50\n",
            "Step 1 / 20, Loss: 0.29233601689338684\n",
            "Step 2 / 20, Loss: 0.3826950490474701\n",
            "Step 3 / 20, Loss: 0.42712563276290894\n",
            "Step 4 / 20, Loss: 0.4243799149990082\n",
            "Step 5 / 20, Loss: 0.38795387744903564\n",
            "Step 6 / 20, Loss: 0.3571082353591919\n",
            "Step 7 / 20, Loss: 0.35254043340682983\n",
            "Step 8 / 20, Loss: 0.3463760018348694\n",
            "Step 9 / 20, Loss: 0.4677843749523163\n",
            "Step 10 / 20, Loss: 0.2867526710033417\n",
            "Step 11 / 20, Loss: 0.31201112270355225\n",
            "Step 12 / 20, Loss: 0.28240394592285156\n",
            "Step 13 / 20, Loss: 0.46341532468795776\n",
            "Step 14 / 20, Loss: 0.4176734685897827\n",
            "Step 15 / 20, Loss: 0.2537541687488556\n",
            "Step 16 / 20, Loss: 0.34266090393066406\n",
            "Step 17 / 20, Loss: 0.41192588210105896\n",
            "Step 18 / 20, Loss: 0.49423831701278687\n",
            "Step 19 / 20, Loss: 0.46396568417549133\n",
            "Step 20 / 20, Loss: 0.3748573362827301\n",
            "Epoch 16/50\n",
            "Step 1 / 20, Loss: 0.3475114405155182\n",
            "Step 2 / 20, Loss: 0.4209580719470978\n",
            "Step 3 / 20, Loss: 0.31509387493133545\n",
            "Step 4 / 20, Loss: 0.2702353894710541\n",
            "Step 5 / 20, Loss: 0.33806151151657104\n",
            "Step 6 / 20, Loss: 0.28879496455192566\n",
            "Step 7 / 20, Loss: 0.32132723927497864\n",
            "Step 8 / 20, Loss: 0.3436615765094757\n",
            "Step 9 / 20, Loss: 0.3369390070438385\n",
            "Step 10 / 20, Loss: 0.3707750737667084\n",
            "Step 11 / 20, Loss: 0.4081742465496063\n",
            "Step 12 / 20, Loss: 0.31324300169944763\n",
            "Step 13 / 20, Loss: 0.24213442206382751\n",
            "Step 14 / 20, Loss: 0.3356131315231323\n",
            "Step 15 / 20, Loss: 0.47629088163375854\n",
            "Step 16 / 20, Loss: 0.5236843824386597\n",
            "Step 17 / 20, Loss: 0.43968722224235535\n",
            "Step 18 / 20, Loss: 0.5694080591201782\n",
            "Step 19 / 20, Loss: 0.40939539670944214\n",
            "Step 20 / 20, Loss: 1.378241777420044\n",
            "Epoch 17/50\n",
            "Step 1 / 20, Loss: 0.37674224376678467\n",
            "Step 2 / 20, Loss: 0.47880294919013977\n",
            "Step 3 / 20, Loss: 0.3173598647117615\n",
            "Step 4 / 20, Loss: 0.2623741030693054\n",
            "Step 5 / 20, Loss: 0.33712083101272583\n",
            "Step 6 / 20, Loss: 0.32013583183288574\n",
            "Step 7 / 20, Loss: 0.39958176016807556\n",
            "Step 8 / 20, Loss: 0.37122464179992676\n",
            "Step 9 / 20, Loss: 0.4034799635410309\n",
            "Step 10 / 20, Loss: 0.31790339946746826\n",
            "Step 11 / 20, Loss: 0.4272257089614868\n",
            "Step 12 / 20, Loss: 0.4018750786781311\n",
            "Step 13 / 20, Loss: 0.41293978691101074\n",
            "Step 14 / 20, Loss: 0.29778149724006653\n",
            "Step 15 / 20, Loss: 0.4614580273628235\n",
            "Step 16 / 20, Loss: 0.4056594967842102\n",
            "Step 17 / 20, Loss: 0.46573707461357117\n",
            "Step 18 / 20, Loss: 0.3253087103366852\n",
            "Step 19 / 20, Loss: 0.34356507658958435\n",
            "Step 20 / 20, Loss: 0.11573150753974915\n",
            "Epoch 18/50\n",
            "Step 1 / 20, Loss: 0.26797759532928467\n",
            "Step 2 / 20, Loss: 0.4793664515018463\n",
            "Step 3 / 20, Loss: 0.2922838628292084\n",
            "Step 4 / 20, Loss: 0.35744744539260864\n",
            "Step 5 / 20, Loss: 0.5808364748954773\n",
            "Step 6 / 20, Loss: 0.4101817011833191\n",
            "Step 7 / 20, Loss: 0.3113142251968384\n",
            "Step 8 / 20, Loss: 0.4421701729297638\n",
            "Step 9 / 20, Loss: 0.2980195879936218\n",
            "Step 10 / 20, Loss: 0.3462960720062256\n",
            "Step 11 / 20, Loss: 0.5353593230247498\n",
            "Step 12 / 20, Loss: 0.348914235830307\n",
            "Step 13 / 20, Loss: 0.23287764191627502\n",
            "Step 14 / 20, Loss: 0.35461586713790894\n",
            "Step 15 / 20, Loss: 0.31786349415779114\n",
            "Step 16 / 20, Loss: 0.43713700771331787\n",
            "Step 17 / 20, Loss: 0.22832882404327393\n",
            "Step 18 / 20, Loss: 0.4014246463775635\n",
            "Step 19 / 20, Loss: 0.43597233295440674\n",
            "Step 20 / 20, Loss: 0.7770770788192749\n",
            "Epoch 19/50\n",
            "Step 1 / 20, Loss: 0.3276750445365906\n",
            "Step 2 / 20, Loss: 0.5007502436637878\n",
            "Step 3 / 20, Loss: 0.29499760270118713\n",
            "Step 4 / 20, Loss: 0.28310060501098633\n",
            "Step 5 / 20, Loss: 0.4581940472126007\n",
            "Step 6 / 20, Loss: 0.3231218457221985\n",
            "Step 7 / 20, Loss: 0.5276807546615601\n",
            "Step 8 / 20, Loss: 0.385975182056427\n",
            "Step 9 / 20, Loss: 0.41067206859588623\n",
            "Step 10 / 20, Loss: 0.4033432900905609\n",
            "Step 11 / 20, Loss: 0.2977493405342102\n",
            "Step 12 / 20, Loss: 0.36470213532447815\n",
            "Step 13 / 20, Loss: 0.3930773138999939\n",
            "Step 14 / 20, Loss: 0.3064822256565094\n",
            "Step 15 / 20, Loss: 0.5096670389175415\n",
            "Step 16 / 20, Loss: 0.39749592542648315\n",
            "Step 17 / 20, Loss: 0.2458391934633255\n",
            "Step 18 / 20, Loss: 0.2972571849822998\n",
            "Step 19 / 20, Loss: 0.30835601687431335\n",
            "Step 20 / 20, Loss: 0.6309427618980408\n",
            "Epoch 20/50\n",
            "Step 1 / 20, Loss: 0.305172860622406\n",
            "Step 2 / 20, Loss: 0.3816891610622406\n",
            "Step 3 / 20, Loss: 0.26063838601112366\n",
            "Step 4 / 20, Loss: 0.3966836631298065\n",
            "Step 5 / 20, Loss: 0.23783010244369507\n",
            "Step 6 / 20, Loss: 0.5250164866447449\n",
            "Step 7 / 20, Loss: 0.29851213097572327\n",
            "Step 8 / 20, Loss: 0.2923056185245514\n",
            "Step 9 / 20, Loss: 0.2781664729118347\n",
            "Step 10 / 20, Loss: 0.24963714182376862\n",
            "Step 11 / 20, Loss: 0.4632999002933502\n",
            "Step 12 / 20, Loss: 0.46472886204719543\n",
            "Step 13 / 20, Loss: 0.4959562420845032\n",
            "Step 14 / 20, Loss: 0.33805447816848755\n",
            "Step 15 / 20, Loss: 0.3504936099052429\n",
            "Step 16 / 20, Loss: 0.461507648229599\n",
            "Step 17 / 20, Loss: 0.49083977937698364\n",
            "Step 18 / 20, Loss: 0.3431338369846344\n",
            "Step 19 / 20, Loss: 0.383333295583725\n",
            "Step 20 / 20, Loss: 0.17255640029907227\n",
            "Epoch 21/50\n",
            "Step 1 / 20, Loss: 0.32392293214797974\n",
            "Step 2 / 20, Loss: 0.3757149875164032\n",
            "Step 3 / 20, Loss: 0.4500054121017456\n",
            "Step 4 / 20, Loss: 0.44289934635162354\n",
            "Step 5 / 20, Loss: 0.4528607130050659\n",
            "Step 6 / 20, Loss: 0.3340613842010498\n",
            "Step 7 / 20, Loss: 0.24270011484622955\n",
            "Step 8 / 20, Loss: 0.40604522824287415\n",
            "Step 9 / 20, Loss: 0.36998817324638367\n",
            "Step 10 / 20, Loss: 0.3579027056694031\n",
            "Step 11 / 20, Loss: 0.36029449105262756\n",
            "Step 12 / 20, Loss: 0.322152316570282\n",
            "Step 13 / 20, Loss: 0.35534676909446716\n",
            "Step 14 / 20, Loss: 0.37776049971580505\n",
            "Step 15 / 20, Loss: 0.2810389995574951\n",
            "Step 16 / 20, Loss: 0.40229931473731995\n",
            "Step 17 / 20, Loss: 0.24726539850234985\n",
            "Step 18 / 20, Loss: 0.480596125125885\n",
            "Step 19 / 20, Loss: 0.3874017000198364\n",
            "Step 20 / 20, Loss: 0.6376314163208008\n",
            "Epoch 22/50\n",
            "Step 1 / 20, Loss: 0.2624443769454956\n",
            "Step 2 / 20, Loss: 0.19187861680984497\n",
            "Step 3 / 20, Loss: 0.2834071218967438\n",
            "Step 4 / 20, Loss: 0.2930837869644165\n",
            "Step 5 / 20, Loss: 0.47111499309539795\n",
            "Step 6 / 20, Loss: 0.5314723253250122\n",
            "Step 7 / 20, Loss: 0.34373340010643005\n",
            "Step 8 / 20, Loss: 0.5000585913658142\n",
            "Step 9 / 20, Loss: 0.376646488904953\n",
            "Step 10 / 20, Loss: 0.37074288725852966\n",
            "Step 11 / 20, Loss: 0.26251348853111267\n",
            "Step 12 / 20, Loss: 0.3342626988887787\n",
            "Step 13 / 20, Loss: 0.46049171686172485\n",
            "Step 14 / 20, Loss: 0.47663915157318115\n",
            "Step 15 / 20, Loss: 0.3190288543701172\n",
            "Step 16 / 20, Loss: 0.3485397398471832\n",
            "Step 17 / 20, Loss: 0.3019532263278961\n",
            "Step 18 / 20, Loss: 0.25049442052841187\n",
            "Step 19 / 20, Loss: 0.5722230672836304\n",
            "Step 20 / 20, Loss: 0.26559215784072876\n",
            "Epoch 23/50\n",
            "Step 1 / 20, Loss: 0.40347129106521606\n",
            "Step 2 / 20, Loss: 0.32908451557159424\n",
            "Step 3 / 20, Loss: 0.3594445288181305\n",
            "Step 4 / 20, Loss: 0.4174478054046631\n",
            "Step 5 / 20, Loss: 0.32760879397392273\n",
            "Step 6 / 20, Loss: 0.41864559054374695\n",
            "Step 7 / 20, Loss: 0.29889339208602905\n",
            "Step 8 / 20, Loss: 0.3698340356349945\n",
            "Step 9 / 20, Loss: 0.31406569480895996\n",
            "Step 10 / 20, Loss: 0.3981432020664215\n",
            "Step 11 / 20, Loss: 0.4252752363681793\n",
            "Step 12 / 20, Loss: 0.3996579349040985\n",
            "Step 13 / 20, Loss: 0.33056750893592834\n",
            "Step 14 / 20, Loss: 0.28768399357795715\n",
            "Step 15 / 20, Loss: 0.4083220958709717\n",
            "Step 16 / 20, Loss: 0.42237144708633423\n",
            "Step 17 / 20, Loss: 0.3385690748691559\n",
            "Step 18 / 20, Loss: 0.3246975839138031\n",
            "Step 19 / 20, Loss: 0.3629084825515747\n",
            "Step 20 / 20, Loss: 0.1220315545797348\n",
            "Epoch 24/50\n",
            "Step 1 / 20, Loss: 0.4582527279853821\n",
            "Step 2 / 20, Loss: 0.30442431569099426\n",
            "Step 3 / 20, Loss: 0.25047650933265686\n",
            "Step 4 / 20, Loss: 0.33347049355506897\n",
            "Step 5 / 20, Loss: 0.29762792587280273\n",
            "Step 6 / 20, Loss: 0.33309653401374817\n",
            "Step 7 / 20, Loss: 0.31262293457984924\n",
            "Step 8 / 20, Loss: 0.4757368862628937\n",
            "Step 9 / 20, Loss: 0.41709911823272705\n",
            "Step 10 / 20, Loss: 0.438186377286911\n",
            "Step 11 / 20, Loss: 0.42067134380340576\n",
            "Step 12 / 20, Loss: 0.5264983177185059\n",
            "Step 13 / 20, Loss: 0.42492377758026123\n",
            "Step 14 / 20, Loss: 0.33115074038505554\n",
            "Step 15 / 20, Loss: 0.3755159378051758\n",
            "Step 16 / 20, Loss: 0.31983983516693115\n",
            "Step 17 / 20, Loss: 0.31985658407211304\n",
            "Step 18 / 20, Loss: 0.24645835161209106\n",
            "Step 19 / 20, Loss: 0.3209381401538849\n",
            "Step 20 / 20, Loss: 0.04984929412603378\n",
            "Epoch 25/50\n",
            "Step 1 / 20, Loss: 0.3831509053707123\n",
            "Step 2 / 20, Loss: 0.20832590758800507\n",
            "Step 3 / 20, Loss: 0.3389164209365845\n",
            "Step 4 / 20, Loss: 0.2605729103088379\n",
            "Step 5 / 20, Loss: 0.29245826601982117\n",
            "Step 6 / 20, Loss: 0.36083170771598816\n",
            "Step 7 / 20, Loss: 0.38381755352020264\n",
            "Step 8 / 20, Loss: 0.34051790833473206\n",
            "Step 9 / 20, Loss: 0.37488824129104614\n",
            "Step 10 / 20, Loss: 0.4444114565849304\n",
            "Step 11 / 20, Loss: 0.25278326869010925\n",
            "Step 12 / 20, Loss: 0.39244261384010315\n",
            "Step 13 / 20, Loss: 0.3105238080024719\n",
            "Step 14 / 20, Loss: 0.21505172550678253\n",
            "Step 15 / 20, Loss: 0.5635899901390076\n",
            "Step 16 / 20, Loss: 0.4375810921192169\n",
            "Step 17 / 20, Loss: 0.4539202153682709\n",
            "Step 18 / 20, Loss: 0.39988768100738525\n",
            "Step 19 / 20, Loss: 0.4506484270095825\n",
            "Step 20 / 20, Loss: 0.48309704661369324\n",
            "Epoch 26/50\n",
            "Step 1 / 20, Loss: 0.3935016691684723\n",
            "Step 2 / 20, Loss: 0.4892723560333252\n",
            "Step 3 / 20, Loss: 0.33068642020225525\n",
            "Step 4 / 20, Loss: 0.3014775812625885\n",
            "Step 5 / 20, Loss: 0.3409227132797241\n",
            "Step 6 / 20, Loss: 0.40174534916877747\n",
            "Step 7 / 20, Loss: 0.3041466474533081\n",
            "Step 8 / 20, Loss: 0.3933509588241577\n",
            "Step 9 / 20, Loss: 0.3444439172744751\n",
            "Step 10 / 20, Loss: 0.267909437417984\n",
            "Step 11 / 20, Loss: 0.319985032081604\n",
            "Step 12 / 20, Loss: 0.31225860118865967\n",
            "Step 13 / 20, Loss: 0.3907433748245239\n",
            "Step 14 / 20, Loss: 0.41855084896087646\n",
            "Step 15 / 20, Loss: 0.3151162266731262\n",
            "Step 16 / 20, Loss: 0.3650948703289032\n",
            "Step 17 / 20, Loss: 0.5028679370880127\n",
            "Step 18 / 20, Loss: 0.3679204285144806\n",
            "Step 19 / 20, Loss: 0.24114690721035004\n",
            "Step 20 / 20, Loss: 1.4684120416641235\n",
            "Epoch 27/50\n",
            "Step 1 / 20, Loss: 0.2984565496444702\n",
            "Step 2 / 20, Loss: 0.4519880712032318\n",
            "Step 3 / 20, Loss: 0.433279424905777\n",
            "Step 4 / 20, Loss: 0.29407739639282227\n",
            "Step 5 / 20, Loss: 0.3198191523551941\n",
            "Step 6 / 20, Loss: 0.48437508940696716\n",
            "Step 7 / 20, Loss: 0.39953896403312683\n",
            "Step 8 / 20, Loss: 0.5323890447616577\n",
            "Step 9 / 20, Loss: 0.24308449029922485\n",
            "Step 10 / 20, Loss: 0.4105551242828369\n",
            "Step 11 / 20, Loss: 0.22375744581222534\n",
            "Step 12 / 20, Loss: 0.35785380005836487\n",
            "Step 13 / 20, Loss: 0.3222944140434265\n",
            "Step 14 / 20, Loss: 0.3816978931427002\n",
            "Step 15 / 20, Loss: 0.4051196575164795\n",
            "Step 16 / 20, Loss: 0.2921222448348999\n",
            "Step 17 / 20, Loss: 0.2344672828912735\n",
            "Step 18 / 20, Loss: 0.3404894769191742\n",
            "Step 19 / 20, Loss: 0.4384619891643524\n",
            "Step 20 / 20, Loss: 0.1570710390806198\n",
            "Epoch 28/50\n",
            "Step 1 / 20, Loss: 0.3635202646255493\n",
            "Step 2 / 20, Loss: 0.44411158561706543\n",
            "Step 3 / 20, Loss: 0.41763144731521606\n",
            "Step 4 / 20, Loss: 0.21828438341617584\n",
            "Step 5 / 20, Loss: 0.4791206419467926\n",
            "Step 6 / 20, Loss: 0.5022097826004028\n",
            "Step 7 / 20, Loss: 0.22992826998233795\n",
            "Step 8 / 20, Loss: 0.3375414311885834\n",
            "Step 9 / 20, Loss: 0.36550652980804443\n",
            "Step 10 / 20, Loss: 0.3345736563205719\n",
            "Step 11 / 20, Loss: 0.2849690020084381\n",
            "Step 12 / 20, Loss: 0.3143066465854645\n",
            "Step 13 / 20, Loss: 0.36639612913131714\n",
            "Step 14 / 20, Loss: 0.3313651978969574\n",
            "Step 15 / 20, Loss: 0.5887362957000732\n",
            "Step 16 / 20, Loss: 0.28383103013038635\n",
            "Step 17 / 20, Loss: 0.31697139143943787\n",
            "Step 18 / 20, Loss: 0.2982000708580017\n",
            "Step 19 / 20, Loss: 0.34505078196525574\n",
            "Step 20 / 20, Loss: 0.13173168897628784\n",
            "Epoch 29/50\n",
            "Step 1 / 20, Loss: 0.32389092445373535\n",
            "Step 2 / 20, Loss: 0.3275502324104309\n",
            "Step 3 / 20, Loss: 0.34613746404647827\n",
            "Step 4 / 20, Loss: 0.3644438087940216\n",
            "Step 5 / 20, Loss: 0.4173698127269745\n",
            "Step 6 / 20, Loss: 0.49429160356521606\n",
            "Step 7 / 20, Loss: 0.2865017056465149\n",
            "Step 8 / 20, Loss: 0.431340754032135\n",
            "Step 9 / 20, Loss: 0.5129291415214539\n",
            "Step 10 / 20, Loss: 0.2732137441635132\n",
            "Step 11 / 20, Loss: 0.24967433512210846\n",
            "Step 12 / 20, Loss: 0.3861483633518219\n",
            "Step 13 / 20, Loss: 0.26759642362594604\n",
            "Step 14 / 20, Loss: 0.3940136730670929\n",
            "Step 15 / 20, Loss: 0.38258638978004456\n",
            "Step 16 / 20, Loss: 0.2891850173473358\n",
            "Step 17 / 20, Loss: 0.3597860634326935\n",
            "Step 18 / 20, Loss: 0.4647640883922577\n",
            "Step 19 / 20, Loss: 0.23039990663528442\n",
            "Step 20 / 20, Loss: 0.0276460200548172\n",
            "Epoch 30/50\n",
            "Step 1 / 20, Loss: 0.3324102461338043\n",
            "Step 2 / 20, Loss: 0.24799314141273499\n",
            "Step 3 / 20, Loss: 0.48933154344558716\n",
            "Step 4 / 20, Loss: 0.41462981700897217\n",
            "Step 5 / 20, Loss: 0.3147604763507843\n",
            "Step 6 / 20, Loss: 0.36066409945487976\n",
            "Step 7 / 20, Loss: 0.27633655071258545\n",
            "Step 8 / 20, Loss: 0.2798754572868347\n",
            "Step 9 / 20, Loss: 0.43835774064064026\n",
            "Step 10 / 20, Loss: 0.34759753942489624\n",
            "Step 11 / 20, Loss: 0.2591022849082947\n",
            "Step 12 / 20, Loss: 0.27304399013519287\n",
            "Step 13 / 20, Loss: 0.3390207290649414\n",
            "Step 14 / 20, Loss: 0.44688427448272705\n",
            "Step 15 / 20, Loss: 0.3434024155139923\n",
            "Step 16 / 20, Loss: 0.46951615810394287\n",
            "Step 17 / 20, Loss: 0.4348668158054352\n",
            "Step 18 / 20, Loss: 0.36237525939941406\n",
            "Step 19 / 20, Loss: 0.3541405200958252\n",
            "Step 20 / 20, Loss: 0.06004203110933304\n",
            "Epoch 31/50\n",
            "Step 1 / 20, Loss: 0.40249383449554443\n",
            "Step 2 / 20, Loss: 0.37340396642684937\n",
            "Step 3 / 20, Loss: 0.35077396035194397\n",
            "Step 4 / 20, Loss: 0.32455429434776306\n",
            "Step 5 / 20, Loss: 0.39019906520843506\n",
            "Step 6 / 20, Loss: 0.3408271372318268\n",
            "Step 7 / 20, Loss: 0.3002263605594635\n",
            "Step 8 / 20, Loss: 0.32617485523223877\n",
            "Step 9 / 20, Loss: 0.21704263985157013\n",
            "Step 10 / 20, Loss: 0.41664355993270874\n",
            "Step 11 / 20, Loss: 0.3613067865371704\n",
            "Step 12 / 20, Loss: 0.35630372166633606\n",
            "Step 13 / 20, Loss: 0.3846226930618286\n",
            "Step 14 / 20, Loss: 0.30645784735679626\n",
            "Step 15 / 20, Loss: 0.30783921480178833\n",
            "Step 16 / 20, Loss: 0.408924400806427\n",
            "Step 17 / 20, Loss: 0.3153110444545746\n",
            "Step 18 / 20, Loss: 0.4783250093460083\n",
            "Step 19 / 20, Loss: 0.3960777223110199\n",
            "Step 20 / 20, Loss: 0.3388473391532898\n",
            "Epoch 32/50\n",
            "Step 1 / 20, Loss: 0.34988242387771606\n",
            "Step 2 / 20, Loss: 0.25438347458839417\n",
            "Step 3 / 20, Loss: 0.362025648355484\n",
            "Step 4 / 20, Loss: 0.34096622467041016\n",
            "Step 5 / 20, Loss: 0.30554673075675964\n",
            "Step 6 / 20, Loss: 0.3162709176540375\n",
            "Step 7 / 20, Loss: 0.35061681270599365\n",
            "Step 8 / 20, Loss: 0.4576020836830139\n",
            "Step 9 / 20, Loss: 0.32957878708839417\n",
            "Step 10 / 20, Loss: 0.3977658152580261\n",
            "Step 11 / 20, Loss: 0.44045907258987427\n",
            "Step 12 / 20, Loss: 0.3576018512248993\n",
            "Step 13 / 20, Loss: 0.4620878994464874\n",
            "Step 14 / 20, Loss: 0.28270766139030457\n",
            "Step 15 / 20, Loss: 0.36347445845603943\n",
            "Step 16 / 20, Loss: 0.3739943206310272\n",
            "Step 17 / 20, Loss: 0.35392722487449646\n",
            "Step 18 / 20, Loss: 0.29427415132522583\n",
            "Step 19 / 20, Loss: 0.3396066427230835\n",
            "Step 20 / 20, Loss: 0.1543472558259964\n",
            "Epoch 33/50\n",
            "Step 1 / 20, Loss: 0.29631081223487854\n",
            "Step 2 / 20, Loss: 0.3936072289943695\n",
            "Step 3 / 20, Loss: 0.39750489592552185\n",
            "Step 4 / 20, Loss: 0.2775432765483856\n",
            "Step 5 / 20, Loss: 0.27159059047698975\n",
            "Step 6 / 20, Loss: 0.40822258591651917\n",
            "Step 7 / 20, Loss: 0.3408869206905365\n",
            "Step 8 / 20, Loss: 0.4203890562057495\n",
            "Step 9 / 20, Loss: 0.2804819941520691\n",
            "Step 10 / 20, Loss: 0.241102397441864\n",
            "Step 11 / 20, Loss: 0.28293347358703613\n",
            "Step 12 / 20, Loss: 0.4891505539417267\n",
            "Step 13 / 20, Loss: 0.4685207009315491\n",
            "Step 14 / 20, Loss: 0.27215656638145447\n",
            "Step 15 / 20, Loss: 0.2814524173736572\n",
            "Step 16 / 20, Loss: 0.41331446170806885\n",
            "Step 17 / 20, Loss: 0.3475942611694336\n",
            "Step 18 / 20, Loss: 0.3626932203769684\n",
            "Step 19 / 20, Loss: 0.4703788459300995\n",
            "Step 20 / 20, Loss: 0.13939546048641205\n",
            "Epoch 34/50\n",
            "Step 1 / 20, Loss: 0.3804725706577301\n",
            "Step 2 / 20, Loss: 0.415321946144104\n",
            "Step 3 / 20, Loss: 0.31240561604499817\n",
            "Step 4 / 20, Loss: 0.4281112253665924\n",
            "Step 5 / 20, Loss: 0.34355831146240234\n",
            "Step 6 / 20, Loss: 0.3944413363933563\n",
            "Step 7 / 20, Loss: 0.2834605574607849\n",
            "Step 8 / 20, Loss: 0.3084625005722046\n",
            "Step 9 / 20, Loss: 0.3460262417793274\n",
            "Step 10 / 20, Loss: 0.26483210921287537\n",
            "Step 11 / 20, Loss: 0.4347299337387085\n",
            "Step 12 / 20, Loss: 0.3713724613189697\n",
            "Step 13 / 20, Loss: 0.28459200263023376\n",
            "Step 14 / 20, Loss: 0.36008575558662415\n",
            "Step 15 / 20, Loss: 0.3943335711956024\n",
            "Step 16 / 20, Loss: 0.30657270550727844\n",
            "Step 17 / 20, Loss: 0.3361895680427551\n",
            "Step 18 / 20, Loss: 0.22440780699253082\n",
            "Step 19 / 20, Loss: 0.4960339367389679\n",
            "Step 20 / 20, Loss: 0.4165002703666687\n",
            "Epoch 35/50\n",
            "Step 1 / 20, Loss: 0.2785031199455261\n",
            "Step 2 / 20, Loss: 0.37250080704689026\n",
            "Step 3 / 20, Loss: 0.3021964430809021\n",
            "Step 4 / 20, Loss: 0.30243003368377686\n",
            "Step 5 / 20, Loss: 0.2907393276691437\n",
            "Step 6 / 20, Loss: 0.3422577381134033\n",
            "Step 7 / 20, Loss: 0.37748345732688904\n",
            "Step 8 / 20, Loss: 0.3979460895061493\n",
            "Step 9 / 20, Loss: 0.30564379692077637\n",
            "Step 10 / 20, Loss: 0.5076658725738525\n",
            "Step 11 / 20, Loss: 0.3848932385444641\n",
            "Step 12 / 20, Loss: 0.2714921832084656\n",
            "Step 13 / 20, Loss: 0.4136814773082733\n",
            "Step 14 / 20, Loss: 0.21313685178756714\n",
            "Step 15 / 20, Loss: 0.4419203996658325\n",
            "Step 16 / 20, Loss: 0.39976969361305237\n",
            "Step 17 / 20, Loss: 0.36453068256378174\n",
            "Step 18 / 20, Loss: 0.3009137213230133\n",
            "Step 19 / 20, Loss: 0.3815426528453827\n",
            "Step 20 / 20, Loss: 0.6092724800109863\n",
            "Epoch 36/50\n",
            "Step 1 / 20, Loss: 0.4808538556098938\n",
            "Step 2 / 20, Loss: 0.4045846164226532\n",
            "Step 3 / 20, Loss: 0.26705771684646606\n",
            "Step 4 / 20, Loss: 0.20711442828178406\n",
            "Step 5 / 20, Loss: 0.3792308568954468\n",
            "Step 6 / 20, Loss: 0.4063137173652649\n",
            "Step 7 / 20, Loss: 0.3205133080482483\n",
            "Step 8 / 20, Loss: 0.3444848358631134\n",
            "Step 9 / 20, Loss: 0.3377559185028076\n",
            "Step 10 / 20, Loss: 0.3729493319988251\n",
            "Step 11 / 20, Loss: 0.3814491331577301\n",
            "Step 12 / 20, Loss: 0.24751931428909302\n",
            "Step 13 / 20, Loss: 0.29877278208732605\n",
            "Step 14 / 20, Loss: 0.3353275656700134\n",
            "Step 15 / 20, Loss: 0.29826995730400085\n",
            "Step 16 / 20, Loss: 0.45421433448791504\n",
            "Step 17 / 20, Loss: 0.5037127137184143\n",
            "Step 18 / 20, Loss: 0.3106219470500946\n",
            "Step 19 / 20, Loss: 0.25315409898757935\n",
            "Step 20 / 20, Loss: 1.352118968963623\n",
            "Epoch 37/50\n",
            "Step 1 / 20, Loss: 0.2776459753513336\n",
            "Step 2 / 20, Loss: 0.4533258080482483\n",
            "Step 3 / 20, Loss: 0.3350954055786133\n",
            "Step 4 / 20, Loss: 0.3353999853134155\n",
            "Step 5 / 20, Loss: 0.2625103294849396\n",
            "Step 6 / 20, Loss: 0.39453548192977905\n",
            "Step 7 / 20, Loss: 0.413461297750473\n",
            "Step 8 / 20, Loss: 0.2800414562225342\n",
            "Step 9 / 20, Loss: 0.34299591183662415\n",
            "Step 10 / 20, Loss: 0.27387526631355286\n",
            "Step 11 / 20, Loss: 0.3378128111362457\n",
            "Step 12 / 20, Loss: 0.46712279319763184\n",
            "Step 13 / 20, Loss: 0.3339720666408539\n",
            "Step 14 / 20, Loss: 0.39992132782936096\n",
            "Step 15 / 20, Loss: 0.27439481019973755\n",
            "Step 16 / 20, Loss: 0.40949109196662903\n",
            "Step 17 / 20, Loss: 0.24100394546985626\n",
            "Step 18 / 20, Loss: 0.30158504843711853\n",
            "Step 19 / 20, Loss: 0.4874688684940338\n",
            "Step 20 / 20, Loss: 0.278423011302948\n",
            "Epoch 38/50\n",
            "Step 1 / 20, Loss: 0.42172691226005554\n",
            "Step 2 / 20, Loss: 0.41054442524909973\n",
            "Step 3 / 20, Loss: 0.29788437485694885\n",
            "Step 4 / 20, Loss: 0.36442825198173523\n",
            "Step 5 / 20, Loss: 0.37656787037849426\n",
            "Step 6 / 20, Loss: 0.3197174072265625\n",
            "Step 7 / 20, Loss: 0.35319769382476807\n",
            "Step 8 / 20, Loss: 0.4496149718761444\n",
            "Step 9 / 20, Loss: 0.28402793407440186\n",
            "Step 10 / 20, Loss: 0.4422411024570465\n",
            "Step 11 / 20, Loss: 0.4236094653606415\n",
            "Step 12 / 20, Loss: 0.35090869665145874\n",
            "Step 13 / 20, Loss: 0.2859814465045929\n",
            "Step 14 / 20, Loss: 0.35499945282936096\n",
            "Step 15 / 20, Loss: 0.24888895452022552\n",
            "Step 16 / 20, Loss: 0.25978267192840576\n",
            "Step 17 / 20, Loss: 0.2691647410392761\n",
            "Step 18 / 20, Loss: 0.30522406101226807\n",
            "Step 19 / 20, Loss: 0.3883422911167145\n",
            "Step 20 / 20, Loss: 0.37920984625816345\n",
            "Epoch 39/50\n",
            "Step 1 / 20, Loss: 0.36605164408683777\n",
            "Step 2 / 20, Loss: 0.3631293475627899\n",
            "Step 3 / 20, Loss: 0.2668572962284088\n",
            "Step 4 / 20, Loss: 0.4131565988063812\n",
            "Step 5 / 20, Loss: 0.24323974549770355\n",
            "Step 6 / 20, Loss: 0.276343435049057\n",
            "Step 7 / 20, Loss: 0.29084789752960205\n",
            "Step 8 / 20, Loss: 0.30367398262023926\n",
            "Step 9 / 20, Loss: 0.26629388332366943\n",
            "Step 10 / 20, Loss: 0.44474324584007263\n",
            "Step 11 / 20, Loss: 0.30849969387054443\n",
            "Step 12 / 20, Loss: 0.3519372045993805\n",
            "Step 13 / 20, Loss: 0.36815115809440613\n",
            "Step 14 / 20, Loss: 0.4055113196372986\n",
            "Step 15 / 20, Loss: 0.4702478051185608\n",
            "Step 16 / 20, Loss: 0.40905293822288513\n",
            "Step 17 / 20, Loss: 0.34163206815719604\n",
            "Step 18 / 20, Loss: 0.38209372758865356\n",
            "Step 19 / 20, Loss: 0.32445093989372253\n",
            "Step 20 / 20, Loss: 0.16979137063026428\n",
            "Epoch 40/50\n",
            "Step 1 / 20, Loss: 0.4250844717025757\n",
            "Step 2 / 20, Loss: 0.21925325691699982\n",
            "Step 3 / 20, Loss: 0.33063870668411255\n",
            "Step 4 / 20, Loss: 0.37168246507644653\n",
            "Step 5 / 20, Loss: 0.5271315574645996\n",
            "Step 6 / 20, Loss: 0.44920113682746887\n",
            "Step 7 / 20, Loss: 0.24064914882183075\n",
            "Step 8 / 20, Loss: 0.3624196946620941\n",
            "Step 9 / 20, Loss: 0.2904735505580902\n",
            "Step 10 / 20, Loss: 0.3058513402938843\n",
            "Step 11 / 20, Loss: 0.3622415065765381\n",
            "Step 12 / 20, Loss: 0.41101568937301636\n",
            "Step 13 / 20, Loss: 0.38418519496917725\n",
            "Step 14 / 20, Loss: 0.34901905059814453\n",
            "Step 15 / 20, Loss: 0.2229171246290207\n",
            "Step 16 / 20, Loss: 0.3256867229938507\n",
            "Step 17 / 20, Loss: 0.4137325584888458\n",
            "Step 18 / 20, Loss: 0.2968806028366089\n",
            "Step 19 / 20, Loss: 0.2927146255970001\n",
            "Step 20 / 20, Loss: 0.13171882927417755\n",
            "Epoch 41/50\n",
            "Step 1 / 20, Loss: 0.41220012307167053\n",
            "Step 2 / 20, Loss: 0.35431602597236633\n",
            "Step 3 / 20, Loss: 0.33447209000587463\n",
            "Step 4 / 20, Loss: 0.24736586213111877\n",
            "Step 5 / 20, Loss: 0.44457268714904785\n",
            "Step 6 / 20, Loss: 0.2627004384994507\n",
            "Step 7 / 20, Loss: 0.23440654575824738\n",
            "Step 8 / 20, Loss: 0.4543709456920624\n",
            "Step 9 / 20, Loss: 0.3333066701889038\n",
            "Step 10 / 20, Loss: 0.22357183694839478\n",
            "Step 11 / 20, Loss: 0.2932654619216919\n",
            "Step 12 / 20, Loss: 0.36850506067276\n",
            "Step 13 / 20, Loss: 0.36572861671447754\n",
            "Step 14 / 20, Loss: 0.3781513273715973\n",
            "Step 15 / 20, Loss: 0.3282303512096405\n",
            "Step 16 / 20, Loss: 0.38424646854400635\n",
            "Step 17 / 20, Loss: 0.3380856215953827\n",
            "Step 18 / 20, Loss: 0.41594958305358887\n",
            "Step 19 / 20, Loss: 0.38187965750694275\n",
            "Step 20 / 20, Loss: 0.12599268555641174\n",
            "Epoch 42/50\n",
            "Step 1 / 20, Loss: 0.35522982478141785\n",
            "Step 2 / 20, Loss: 0.23282648622989655\n",
            "Step 3 / 20, Loss: 0.3468177318572998\n",
            "Step 4 / 20, Loss: 0.4483290910720825\n",
            "Step 5 / 20, Loss: 0.3335023522377014\n",
            "Step 6 / 20, Loss: 0.28998684883117676\n",
            "Step 7 / 20, Loss: 0.40121763944625854\n",
            "Step 8 / 20, Loss: 0.3469512164592743\n",
            "Step 9 / 20, Loss: 0.29153046011924744\n",
            "Step 10 / 20, Loss: 0.3949616551399231\n",
            "Step 11 / 20, Loss: 0.29158493876457214\n",
            "Step 12 / 20, Loss: 0.2767050266265869\n",
            "Step 13 / 20, Loss: 0.4133744537830353\n",
            "Step 14 / 20, Loss: 0.3768482506275177\n",
            "Step 15 / 20, Loss: 0.33756905794143677\n",
            "Step 16 / 20, Loss: 0.3354484438896179\n",
            "Step 17 / 20, Loss: 0.2300734668970108\n",
            "Step 18 / 20, Loss: 0.4217795431613922\n",
            "Step 19 / 20, Loss: 0.35895147919654846\n",
            "Step 20 / 20, Loss: 1.4716970920562744\n",
            "Epoch 43/50\n",
            "Step 1 / 20, Loss: 0.36473578214645386\n",
            "Step 2 / 20, Loss: 0.5187328457832336\n",
            "Step 3 / 20, Loss: 0.24348925054073334\n",
            "Step 4 / 20, Loss: 0.4973798990249634\n",
            "Step 5 / 20, Loss: 0.229098841547966\n",
            "Step 6 / 20, Loss: 0.3740386664867401\n",
            "Step 7 / 20, Loss: 0.32449835538864136\n",
            "Step 8 / 20, Loss: 0.39651545882225037\n",
            "Step 9 / 20, Loss: 0.34331563115119934\n",
            "Step 10 / 20, Loss: 0.34424513578414917\n",
            "Step 11 / 20, Loss: 0.32147955894470215\n",
            "Step 12 / 20, Loss: 0.28342339396476746\n",
            "Step 13 / 20, Loss: 0.28117331862449646\n",
            "Step 14 / 20, Loss: 0.3756445348262787\n",
            "Step 15 / 20, Loss: 0.36802294850349426\n",
            "Step 16 / 20, Loss: 0.293712854385376\n",
            "Step 17 / 20, Loss: 0.3189365267753601\n",
            "Step 18 / 20, Loss: 0.3224058449268341\n",
            "Step 19 / 20, Loss: 0.3178577721118927\n",
            "Step 20 / 20, Loss: 0.14484503865242004\n",
            "Epoch 44/50\n",
            "Step 1 / 20, Loss: 0.3340548276901245\n",
            "Step 2 / 20, Loss: 0.465188205242157\n",
            "Step 3 / 20, Loss: 0.26393502950668335\n",
            "Step 4 / 20, Loss: 0.26162394881248474\n",
            "Step 5 / 20, Loss: 0.3186722695827484\n",
            "Step 6 / 20, Loss: 0.3877622187137604\n",
            "Step 7 / 20, Loss: 0.4234321713447571\n",
            "Step 8 / 20, Loss: 0.3017615079879761\n",
            "Step 9 / 20, Loss: 0.45820340514183044\n",
            "Step 10 / 20, Loss: 0.38156792521476746\n",
            "Step 11 / 20, Loss: 0.41205596923828125\n",
            "Step 12 / 20, Loss: 0.33169689774513245\n",
            "Step 13 / 20, Loss: 0.30290988087654114\n",
            "Step 14 / 20, Loss: 0.28060248494148254\n",
            "Step 15 / 20, Loss: 0.3840014636516571\n",
            "Step 16 / 20, Loss: 0.2990765869617462\n",
            "Step 17 / 20, Loss: 0.31856995820999146\n",
            "Step 18 / 20, Loss: 0.2564961016178131\n",
            "Step 19 / 20, Loss: 0.3232758343219757\n",
            "Step 20 / 20, Loss: 0.06626159697771072\n",
            "Epoch 45/50\n",
            "Step 1 / 20, Loss: 0.34525418281555176\n",
            "Step 2 / 20, Loss: 0.4983822703361511\n",
            "Step 3 / 20, Loss: 0.23471680283546448\n",
            "Step 4 / 20, Loss: 0.33209705352783203\n",
            "Step 5 / 20, Loss: 0.38425150513648987\n",
            "Step 6 / 20, Loss: 0.2748287320137024\n",
            "Step 7 / 20, Loss: 0.21398183703422546\n",
            "Step 8 / 20, Loss: 0.46828994154930115\n",
            "Step 9 / 20, Loss: 0.5527920722961426\n",
            "Step 10 / 20, Loss: 0.29734477400779724\n",
            "Step 11 / 20, Loss: 0.445821613073349\n",
            "Step 12 / 20, Loss: 0.2343006730079651\n",
            "Step 13 / 20, Loss: 0.34616783261299133\n",
            "Step 14 / 20, Loss: 0.2954142987728119\n",
            "Step 15 / 20, Loss: 0.3312331438064575\n",
            "Step 16 / 20, Loss: 0.2590440511703491\n",
            "Step 17 / 20, Loss: 0.29916441440582275\n",
            "Step 18 / 20, Loss: 0.2889314293861389\n",
            "Step 19 / 20, Loss: 0.3759573698043823\n",
            "Step 20 / 20, Loss: 0.07636372745037079\n",
            "Epoch 46/50\n",
            "Step 1 / 20, Loss: 0.3697204291820526\n",
            "Step 2 / 20, Loss: 0.24227525293827057\n",
            "Step 3 / 20, Loss: 0.2947673797607422\n",
            "Step 4 / 20, Loss: 0.23222151398658752\n",
            "Step 5 / 20, Loss: 0.40579700469970703\n",
            "Step 6 / 20, Loss: 0.5214769840240479\n",
            "Step 7 / 20, Loss: 0.2852807939052582\n",
            "Step 8 / 20, Loss: 0.35549676418304443\n",
            "Step 9 / 20, Loss: 0.32220420241355896\n",
            "Step 10 / 20, Loss: 0.4125504195690155\n",
            "Step 11 / 20, Loss: 0.1892046481370926\n",
            "Step 12 / 20, Loss: 0.27719080448150635\n",
            "Step 13 / 20, Loss: 0.2988058030605316\n",
            "Step 14 / 20, Loss: 0.29152941703796387\n",
            "Step 15 / 20, Loss: 0.32288697361946106\n",
            "Step 16 / 20, Loss: 0.33075305819511414\n",
            "Step 17 / 20, Loss: 0.5748870372772217\n",
            "Step 18 / 20, Loss: 0.436600923538208\n",
            "Step 19 / 20, Loss: 0.2925943434238434\n",
            "Step 20 / 20, Loss: 0.3792567253112793\n",
            "Epoch 47/50\n",
            "Step 1 / 20, Loss: 0.3148099184036255\n",
            "Step 2 / 20, Loss: 0.31354305148124695\n",
            "Step 3 / 20, Loss: 0.31466764211654663\n",
            "Step 4 / 20, Loss: 0.6591255068778992\n",
            "Step 5 / 20, Loss: 0.35340645909309387\n",
            "Step 6 / 20, Loss: 0.3254351019859314\n",
            "Step 7 / 20, Loss: 0.26559630036354065\n",
            "Step 8 / 20, Loss: 0.33721500635147095\n",
            "Step 9 / 20, Loss: 0.23111219704151154\n",
            "Step 10 / 20, Loss: 0.30042046308517456\n",
            "Step 11 / 20, Loss: 0.37347346544265747\n",
            "Step 12 / 20, Loss: 0.378663569688797\n",
            "Step 13 / 20, Loss: 0.4147244691848755\n",
            "Step 14 / 20, Loss: 0.28998827934265137\n",
            "Step 15 / 20, Loss: 0.3145068287849426\n",
            "Step 16 / 20, Loss: 0.26291465759277344\n",
            "Step 17 / 20, Loss: 0.3321770131587982\n",
            "Step 18 / 20, Loss: 0.34820008277893066\n",
            "Step 19 / 20, Loss: 0.28122854232788086\n",
            "Step 20 / 20, Loss: 0.9646055698394775\n",
            "Epoch 48/50\n",
            "Step 1 / 20, Loss: 0.33297207951545715\n",
            "Step 2 / 20, Loss: 0.5235636234283447\n",
            "Step 3 / 20, Loss: 0.42407768964767456\n",
            "Step 4 / 20, Loss: 0.2277996838092804\n",
            "Step 5 / 20, Loss: 0.27706584334373474\n",
            "Step 6 / 20, Loss: 0.3688463270664215\n",
            "Step 7 / 20, Loss: 0.3574245870113373\n",
            "Step 8 / 20, Loss: 0.40520671010017395\n",
            "Step 9 / 20, Loss: 0.35052409768104553\n",
            "Step 10 / 20, Loss: 0.2661381661891937\n",
            "Step 11 / 20, Loss: 0.4123326539993286\n",
            "Step 12 / 20, Loss: 0.31025561690330505\n",
            "Step 13 / 20, Loss: 0.3311689794063568\n",
            "Step 14 / 20, Loss: 0.2475176751613617\n",
            "Step 15 / 20, Loss: 0.2120649218559265\n",
            "Step 16 / 20, Loss: 0.28045737743377686\n",
            "Step 17 / 20, Loss: 0.3723316490650177\n",
            "Step 18 / 20, Loss: 0.35875213146209717\n",
            "Step 19 / 20, Loss: 0.37418198585510254\n",
            "Step 20 / 20, Loss: 0.13940945267677307\n",
            "Epoch 49/50\n",
            "Step 1 / 20, Loss: 0.264341801404953\n",
            "Step 2 / 20, Loss: 0.3674173355102539\n",
            "Step 3 / 20, Loss: 0.5153203010559082\n",
            "Step 4 / 20, Loss: 0.3610585033893585\n",
            "Step 5 / 20, Loss: 0.4843452572822571\n",
            "Step 6 / 20, Loss: 0.37996333837509155\n",
            "Step 7 / 20, Loss: 0.3121621012687683\n",
            "Step 8 / 20, Loss: 0.378707617521286\n",
            "Step 9 / 20, Loss: 0.2840801477432251\n",
            "Step 10 / 20, Loss: 0.24816104769706726\n",
            "Step 11 / 20, Loss: 0.3278423249721527\n",
            "Step 12 / 20, Loss: 0.39189204573631287\n",
            "Step 13 / 20, Loss: 0.3128197491168976\n",
            "Step 14 / 20, Loss: 0.23114123940467834\n",
            "Step 15 / 20, Loss: 0.386144757270813\n",
            "Step 16 / 20, Loss: 0.2953189015388489\n",
            "Step 17 / 20, Loss: 0.2531600296497345\n",
            "Step 18 / 20, Loss: 0.25129061937332153\n",
            "Step 19 / 20, Loss: 0.3473147451877594\n",
            "Step 20 / 20, Loss: 0.4384266138076782\n",
            "Epoch 50/50\n",
            "Step 1 / 20, Loss: 0.33379366993904114\n",
            "Step 2 / 20, Loss: 0.43867045640945435\n",
            "Step 3 / 20, Loss: 0.3368382155895233\n",
            "Step 4 / 20, Loss: 0.24142883718013763\n",
            "Step 5 / 20, Loss: 0.36075738072395325\n",
            "Step 6 / 20, Loss: 0.3645099401473999\n",
            "Step 7 / 20, Loss: 0.30566373467445374\n",
            "Step 8 / 20, Loss: 0.20433486998081207\n",
            "Step 9 / 20, Loss: 0.26083293557167053\n",
            "Step 10 / 20, Loss: 0.2751075327396393\n",
            "Step 11 / 20, Loss: 0.46230965852737427\n",
            "Step 12 / 20, Loss: 0.36874762177467346\n",
            "Step 13 / 20, Loss: 0.4830719232559204\n",
            "Step 14 / 20, Loss: 0.4475353956222534\n",
            "Step 15 / 20, Loss: 0.29525160789489746\n",
            "Step 16 / 20, Loss: 0.3945140838623047\n",
            "Step 17 / 20, Loss: 0.17655152082443237\n",
            "Step 18 / 20, Loss: 0.36915475130081177\n",
            "Step 19 / 20, Loss: 0.2557429075241089\n",
            "Step 20 / 20, Loss: 0.5141798257827759\n"
          ]
        }
      ],
      "source": [
        "#Epochs are the total number of times the algorithm goes through the whole set\n",
        "# 5-10 epochs will indicate underfitting and how much can be learned quickly\n",
        "# 50 epochs will sufficiently catch complex patterns without overfitting\n",
        "# 200+ will point out overfitting\n",
        "NUM_EPOCHS = int(input(\"How many epochs: \"))\n",
        "losses = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
        "\n",
        "        # Convert input data to float32\n",
        "        X_batch = X_batch.float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = loss_function(outputs, y_batch.unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        print(f'Step {i+1} / {len(train_loader)}, Loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJv4xDgjkuer",
        "outputId": "2a05d1e0-b299-4fa9-e5ff-25a2855ed3c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy:  85.92436974789915\n",
            "Valid accuracy:  85.71428571428571\n",
            "Test accuracy:  89.91596638655463\n"
          ]
        }
      ],
      "source": [
        "# Define function to get accuracy\n",
        "def get_accuracy(data_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
        "\n",
        "            # Convert input data to float32\n",
        "            X_batch = X_batch.float()\n",
        "\n",
        "            outputs = model(X_batch)\n",
        "            predicted = torch.round(outputs)\n",
        "            correct += (predicted == y_batch.unsqueeze(1)).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "    return (correct / total) * 100\n",
        "\n",
        "# Calculate accuracy on train, validation, and test sets\n",
        "train_accuracy = get_accuracy(train_loader)\n",
        "valid_accuracy = get_accuracy(valid_loader)\n",
        "test_accuracy = get_accuracy(test_loader)\n",
        "\n",
        "print(\"Train accuracy: \", train_accuracy)\n",
        "print(\"Valid accuracy: \", valid_accuracy)\n",
        "print(\"Test accuracy: \", test_accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
